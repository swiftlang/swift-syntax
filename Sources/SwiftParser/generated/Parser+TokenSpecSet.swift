//// Automatically generated by generate-swift-syntax
//// Do not edit directly!
//===----------------------------------------------------------------------===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2014 - 2023 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//

#if swift(>=6)
@_spi(RawSyntax) @_spi(ExperimentalLanguageFeatures) public import SwiftSyntax
#else
@_spi(RawSyntax) @_spi(ExperimentalLanguageFeatures) import SwiftSyntax
#endif

extension AccessorDeclSyntax {
  @_spi(Diagnostics)
  public enum AccessorSpecifierOptions: TokenSpecSet {
    case get
    case set
    case didSet
    case willSet
    case unsafeAddress
    case addressWithOwner
    case addressWithNativeOwner
    case unsafeMutableAddress
    case mutableAddressWithOwner
    case mutableAddressWithNativeOwner
    case _read
    case _modify
    #if compiler(>=5.8)
    @_spi(ExperimentalLanguageFeatures)
    #endif
    case modify
    case `init`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.get):
        self = .get
      case TokenSpec(.set):
        self = .set
      case TokenSpec(.didSet):
        self = .didSet
      case TokenSpec(.willSet):
        self = .willSet
      case TokenSpec(.unsafeAddress):
        self = .unsafeAddress
      case TokenSpec(.addressWithOwner):
        self = .addressWithOwner
      case TokenSpec(.addressWithNativeOwner):
        self = .addressWithNativeOwner
      case TokenSpec(.unsafeMutableAddress):
        self = .unsafeMutableAddress
      case TokenSpec(.mutableAddressWithOwner):
        self = .mutableAddressWithOwner
      case TokenSpec(.mutableAddressWithNativeOwner):
        self = .mutableAddressWithNativeOwner
      case TokenSpec(._read):
        self = ._read
      case TokenSpec(._modify):
        self = ._modify
      case TokenSpec(.modify) where experimentalFeatures.contains(.coroutineAccessors):
        self = .modify
      case TokenSpec(.`init`):
        self = .`init`
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.get):
        self = .get
      case TokenSpec(.set):
        self = .set
      case TokenSpec(.didSet):
        self = .didSet
      case TokenSpec(.willSet):
        self = .willSet
      case TokenSpec(.unsafeAddress):
        self = .unsafeAddress
      case TokenSpec(.addressWithOwner):
        self = .addressWithOwner
      case TokenSpec(.addressWithNativeOwner):
        self = .addressWithNativeOwner
      case TokenSpec(.unsafeMutableAddress):
        self = .unsafeMutableAddress
      case TokenSpec(.mutableAddressWithOwner):
        self = .mutableAddressWithOwner
      case TokenSpec(.mutableAddressWithNativeOwner):
        self = .mutableAddressWithNativeOwner
      case TokenSpec(._read):
        self = ._read
      case TokenSpec(._modify):
        self = ._modify
      case TokenSpec(.modify):
        self = .modify
      case TokenSpec(.`init`):
        self = .`init`
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      case .didSet:
        return .keyword(.didSet)
      case .willSet:
        return .keyword(.willSet)
      case .unsafeAddress:
        return .keyword(.unsafeAddress)
      case .addressWithOwner:
        return .keyword(.addressWithOwner)
      case .addressWithNativeOwner:
        return .keyword(.addressWithNativeOwner)
      case .unsafeMutableAddress:
        return .keyword(.unsafeMutableAddress)
      case .mutableAddressWithOwner:
        return .keyword(.mutableAddressWithOwner)
      case .mutableAddressWithNativeOwner:
        return .keyword(.mutableAddressWithNativeOwner)
      case ._read:
        return .keyword(._read)
      case ._modify:
        return .keyword(._modify)
      case .modify:
        return .keyword(.modify)
      case .`init`:
        return .keyword(.`init`)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      case .didSet:
        return .keyword(.didSet)
      case .willSet:
        return .keyword(.willSet)
      case .unsafeAddress:
        return .keyword(.unsafeAddress)
      case .addressWithOwner:
        return .keyword(.addressWithOwner)
      case .addressWithNativeOwner:
        return .keyword(.addressWithNativeOwner)
      case .unsafeMutableAddress:
        return .keyword(.unsafeMutableAddress)
      case .mutableAddressWithOwner:
        return .keyword(.mutableAddressWithOwner)
      case .mutableAddressWithNativeOwner:
        return .keyword(.mutableAddressWithNativeOwner)
      case ._read:
        return .keyword(._read)
      case ._modify:
        return .keyword(._modify)
      case .modify:
        return .keyword(.modify)
      case .`init`:
        return .keyword(.`init`)
      }
    }
  }
}

extension AsExprSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension AvailabilityConditionSyntax {
  @_spi(Diagnostics)
  public enum AvailabilityKeywordOptions: TokenSpecSet {
    case poundAvailable
    case poundUnavailable

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.poundAvailable):
        self = .poundAvailable
      case TokenSpec(.poundUnavailable):
        self = .poundUnavailable
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.poundAvailable):
        self = .poundAvailable
      case TokenSpec(.poundUnavailable):
        self = .poundUnavailable
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .poundAvailable:
        return .poundAvailable
      case .poundUnavailable:
        return .poundUnavailable
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .poundAvailable:
        return .poundAvailableToken()
      case .poundUnavailable:
        return .poundUnavailableToken()
      }
    }
  }
}

extension AvailabilityLabeledArgumentSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case message
    case renamed
    case introduced
    case obsoleted
    case deprecated

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.message):
        self = .message
      case TokenSpec(.renamed):
        self = .renamed
      case TokenSpec(.introduced):
        self = .introduced
      case TokenSpec(.obsoleted):
        self = .obsoleted
      case TokenSpec(.deprecated):
        self = .deprecated
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.message):
        self = .message
      case TokenSpec(.renamed):
        self = .renamed
      case TokenSpec(.introduced):
        self = .introduced
      case TokenSpec(.obsoleted):
        self = .obsoleted
      case TokenSpec(.deprecated):
        self = .deprecated
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .message:
        return .keyword(.message)
      case .renamed:
        return .keyword(.renamed)
      case .introduced:
        return .keyword(.introduced)
      case .obsoleted:
        return .keyword(.obsoleted)
      case .deprecated:
        return .keyword(.deprecated)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .message:
        return .keyword(.message)
      case .renamed:
        return .keyword(.renamed)
      case .introduced:
        return .keyword(.introduced)
      case .obsoleted:
        return .keyword(.obsoleted)
      case .deprecated:
        return .keyword(.deprecated)
      }
    }
  }
}

extension BooleanLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum LiteralOptions: TokenSpecSet {
    case `true`
    case `false`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.true):
        self = .true
      case TokenSpec(.false):
        self = .false
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.true):
        self = .true
      case TokenSpec(.false):
        self = .false
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .true:
        return .keyword(.true)
      case .false:
        return .keyword(.false)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .true:
        return .keyword(.true)
      case .false:
        return .keyword(.false)
      }
    }
  }
}

extension _CanImportVersionInfoSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case _version
    case _underlyingVersion

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._version):
        self = ._version
      case TokenSpec(._underlyingVersion):
        self = ._underlyingVersion
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(._version):
        self = ._version
      case TokenSpec(._underlyingVersion):
        self = ._underlyingVersion
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case ._version:
        return .keyword(._version)
      case ._underlyingVersion:
        return .keyword(._underlyingVersion)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._version:
        return .keyword(._version)
      case ._underlyingVersion:
        return .keyword(._underlyingVersion)
      }
    }
  }
}

extension ClosureCaptureSpecifierSyntax {
  @_spi(Diagnostics)
  public enum SpecifierOptions: TokenSpecSet {
    case weak
    case unowned

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.weak):
        self = .weak
      case TokenSpec(.unowned):
        self = .unowned
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.weak):
        self = .weak
      case TokenSpec(.unowned):
        self = .unowned
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .weak:
        return .keyword(.weak)
      case .unowned:
        return .keyword(.unowned)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .weak:
        return .keyword(.weak)
      case .unowned:
        return .keyword(.unowned)
      }
    }
  }
}

extension ClosureCaptureSpecifierSyntax {
  @_spi(Diagnostics)
  public enum DetailOptions: TokenSpecSet {
    case safe
    case unsafe

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.safe):
        self = .safe
      case TokenSpec(.unsafe):
        self = .unsafe
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.safe):
        self = .safe
      case TokenSpec(.unsafe):
        self = .unsafe
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .safe:
        return .keyword(.safe)
      case .unsafe:
        return .keyword(.unsafe)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .safe:
        return .keyword(.safe)
      case .unsafe:
        return .keyword(.unsafe)
      }
    }
  }
}

extension ClosureCaptureSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case `self`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .keyword(.self)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      }
    }
  }
}

extension ClosureParameterSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension ClosureParameterSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension ClosureShorthandParameterSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension ConsumeExprSyntax {
  @_spi(Diagnostics)
  public enum ConsumeKeywordOptions: TokenSpecSet {
    case _move
    case consume

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._move):
        self = ._move
      case TokenSpec(.consume):
        self = .consume
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(._move):
        self = ._move
      case TokenSpec(.consume):
        self = .consume
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case ._move:
        return .keyword(._move)
      case .consume:
        return .keyword(.consume)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._move:
        return .keyword(._move)
      case .consume:
        return .keyword(.consume)
      }
    }
  }
}

extension DeclModifierSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case __consuming
    case __setter_access
    case _const
    case _local
    case actor
    case async
    case borrowing
    case `class`
    case consuming
    case convenience
    case distributed
    case dynamic
    case `fileprivate`
    case final
    case indirect
    case infix
    case `internal`
    case isolated
    case lazy
    case mutating
    case nonisolated
    case nonmutating
    case open
    case optional
    case override
    case package
    case postfix
    case prefix
    case `private`
    case `public`
    case reasync
    case required
    case `static`
    case unowned
    case weak
    case sending

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.__consuming):
        self = .__consuming
      case TokenSpec(.__setter_access):
        self = .__setter_access
      case TokenSpec(._const):
        self = ._const
      case TokenSpec(._local):
        self = ._local
      case TokenSpec(.actor):
        self = .actor
      case TokenSpec(.async):
        self = .async
      case TokenSpec(.borrowing):
        self = .borrowing
      case TokenSpec(.class):
        self = .class
      case TokenSpec(.consuming):
        self = .consuming
      case TokenSpec(.convenience):
        self = .convenience
      case TokenSpec(.distributed):
        self = .distributed
      case TokenSpec(.dynamic):
        self = .dynamic
      case TokenSpec(.fileprivate):
        self = .fileprivate
      case TokenSpec(.final):
        self = .final
      case TokenSpec(.indirect):
        self = .indirect
      case TokenSpec(.infix):
        self = .infix
      case TokenSpec(.internal):
        self = .internal
      case TokenSpec(.isolated):
        self = .isolated
      case TokenSpec(.lazy):
        self = .lazy
      case TokenSpec(.mutating):
        self = .mutating
      case TokenSpec(.nonisolated):
        self = .nonisolated
      case TokenSpec(.nonmutating):
        self = .nonmutating
      case TokenSpec(.open):
        self = .open
      case TokenSpec(.optional):
        self = .optional
      case TokenSpec(.override):
        self = .override
      case TokenSpec(.package):
        self = .package
      case TokenSpec(.postfix):
        self = .postfix
      case TokenSpec(.prefix):
        self = .prefix
      case TokenSpec(.private):
        self = .private
      case TokenSpec(.public):
        self = .public
      case TokenSpec(.reasync):
        self = .reasync
      case TokenSpec(.required):
        self = .required
      case TokenSpec(.static):
        self = .static
      case TokenSpec(.unowned):
        self = .unowned
      case TokenSpec(.weak):
        self = .weak
      case TokenSpec(.sending):
        self = .sending
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.__consuming):
        self = .__consuming
      case TokenSpec(.__setter_access):
        self = .__setter_access
      case TokenSpec(._const):
        self = ._const
      case TokenSpec(._local):
        self = ._local
      case TokenSpec(.actor):
        self = .actor
      case TokenSpec(.async):
        self = .async
      case TokenSpec(.borrowing):
        self = .borrowing
      case TokenSpec(.class):
        self = .class
      case TokenSpec(.consuming):
        self = .consuming
      case TokenSpec(.convenience):
        self = .convenience
      case TokenSpec(.distributed):
        self = .distributed
      case TokenSpec(.dynamic):
        self = .dynamic
      case TokenSpec(.fileprivate):
        self = .fileprivate
      case TokenSpec(.final):
        self = .final
      case TokenSpec(.indirect):
        self = .indirect
      case TokenSpec(.infix):
        self = .infix
      case TokenSpec(.internal):
        self = .internal
      case TokenSpec(.isolated):
        self = .isolated
      case TokenSpec(.lazy):
        self = .lazy
      case TokenSpec(.mutating):
        self = .mutating
      case TokenSpec(.nonisolated):
        self = .nonisolated
      case TokenSpec(.nonmutating):
        self = .nonmutating
      case TokenSpec(.open):
        self = .open
      case TokenSpec(.optional):
        self = .optional
      case TokenSpec(.override):
        self = .override
      case TokenSpec(.package):
        self = .package
      case TokenSpec(.postfix):
        self = .postfix
      case TokenSpec(.prefix):
        self = .prefix
      case TokenSpec(.private):
        self = .private
      case TokenSpec(.public):
        self = .public
      case TokenSpec(.reasync):
        self = .reasync
      case TokenSpec(.required):
        self = .required
      case TokenSpec(.static):
        self = .static
      case TokenSpec(.unowned):
        self = .unowned
      case TokenSpec(.weak):
        self = .weak
      case TokenSpec(.sending):
        self = .sending
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .__consuming:
        return .keyword(.__consuming)
      case .__setter_access:
        return .keyword(.__setter_access)
      case ._const:
        return .keyword(._const)
      case ._local:
        return .keyword(._local)
      case .actor:
        return .keyword(.actor)
      case .async:
        return .keyword(.async)
      case .borrowing:
        return .keyword(.borrowing)
      case .class:
        return .keyword(.class)
      case .consuming:
        return .keyword(.consuming)
      case .convenience:
        return .keyword(.convenience)
      case .distributed:
        return .keyword(.distributed)
      case .dynamic:
        return .keyword(.dynamic)
      case .fileprivate:
        return .keyword(.fileprivate)
      case .final:
        return .keyword(.final)
      case .indirect:
        return .keyword(.indirect)
      case .infix:
        return .keyword(.infix)
      case .internal:
        return .keyword(.internal)
      case .isolated:
        return .keyword(.isolated)
      case .lazy:
        return .keyword(.lazy)
      case .mutating:
        return .keyword(.mutating)
      case .nonisolated:
        return .keyword(.nonisolated)
      case .nonmutating:
        return .keyword(.nonmutating)
      case .open:
        return .keyword(.open)
      case .optional:
        return .keyword(.optional)
      case .override:
        return .keyword(.override)
      case .package:
        return .keyword(.package)
      case .postfix:
        return .keyword(.postfix)
      case .prefix:
        return .keyword(.prefix)
      case .private:
        return .keyword(.private)
      case .public:
        return .keyword(.public)
      case .reasync:
        return .keyword(.reasync)
      case .required:
        return .keyword(.required)
      case .static:
        return .keyword(.static)
      case .unowned:
        return .keyword(.unowned)
      case .weak:
        return .keyword(.weak)
      case .sending:
        return .keyword(.sending)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .__consuming:
        return .keyword(.__consuming)
      case .__setter_access:
        return .keyword(.__setter_access)
      case ._const:
        return .keyword(._const)
      case ._local:
        return .keyword(._local)
      case .actor:
        return .keyword(.actor)
      case .async:
        return .keyword(.async)
      case .borrowing:
        return .keyword(.borrowing)
      case .class:
        return .keyword(.class)
      case .consuming:
        return .keyword(.consuming)
      case .convenience:
        return .keyword(.convenience)
      case .distributed:
        return .keyword(.distributed)
      case .dynamic:
        return .keyword(.dynamic)
      case .fileprivate:
        return .keyword(.fileprivate)
      case .final:
        return .keyword(.final)
      case .indirect:
        return .keyword(.indirect)
      case .infix:
        return .keyword(.infix)
      case .internal:
        return .keyword(.internal)
      case .isolated:
        return .keyword(.isolated)
      case .lazy:
        return .keyword(.lazy)
      case .mutating:
        return .keyword(.mutating)
      case .nonisolated:
        return .keyword(.nonisolated)
      case .nonmutating:
        return .keyword(.nonmutating)
      case .open:
        return .keyword(.open)
      case .optional:
        return .keyword(.optional)
      case .override:
        return .keyword(.override)
      case .package:
        return .keyword(.package)
      case .postfix:
        return .keyword(.postfix)
      case .prefix:
        return .keyword(.prefix)
      case .private:
        return .keyword(.private)
      case .public:
        return .keyword(.public)
      case .reasync:
        return .keyword(.reasync)
      case .required:
        return .keyword(.required)
      case .static:
        return .keyword(.static)
      case .unowned:
        return .keyword(.unowned)
      case .weak:
        return .keyword(.weak)
      case .sending:
        return .keyword(.sending)
      }
    }
  }
}

extension DeclReferenceExprSyntax {
  @_spi(Diagnostics)
  public enum BaseNameOptions: TokenSpecSet {
    case identifier
    case `self`
    case `Self`
    case `init`
    case `deinit`
    case `subscript`
    case dollarIdentifier
    case binaryOperator
    case integerLiteral

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      case TokenSpec(.Self):
        self = .Self
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.deinit):
        self = .deinit
      case TokenSpec(.subscript):
        self = .subscript
      case TokenSpec(.dollarIdentifier):
        self = .dollarIdentifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      case TokenSpec(.Self):
        self = .Self
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.deinit):
        self = .deinit
      case TokenSpec(.subscript):
        self = .subscript
      case TokenSpec(.dollarIdentifier):
        self = .dollarIdentifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .keyword(.self)
      case .Self:
        return .keyword(.Self)
      case .`init`:
        return .keyword(.`init`)
      case .deinit:
        return .keyword(.deinit)
      case .subscript:
        return .keyword(.subscript)
      case .dollarIdentifier:
        return .dollarIdentifier
      case .binaryOperator:
        return .binaryOperator
      case .integerLiteral:
        return .integerLiteral
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      case .Self:
        return .keyword(.Self)
      case .`init`:
        return .keyword(.`init`)
      case .deinit:
        return .keyword(.deinit)
      case .subscript:
        return .keyword(.subscript)
      case .dollarIdentifier:
        return .dollarIdentifier("")
      case .binaryOperator:
        return .binaryOperator("")
      case .integerLiteral:
        return .integerLiteral("")
      }
    }
  }
}

extension DerivativeAttributeArgumentsSyntax {
  @_spi(Diagnostics)
  public enum AccessorSpecifierOptions: TokenSpecSet {
    case get
    case set

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.get):
        self = .get
      case TokenSpec(.set):
        self = .set
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.get):
        self = .get
      case TokenSpec(.set):
        self = .set
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      }
    }
  }
}

extension DifferentiabilityArgumentSyntax {
  @_spi(Diagnostics)
  public enum ArgumentOptions: TokenSpecSet {
    case identifier
    case integerLiteral
    case `self`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      case TokenSpec(.self):
        self = .self
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      case TokenSpec(.self):
        self = .self
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .integerLiteral:
        return .integerLiteral
      case .self:
        return .keyword(.self)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .integerLiteral:
        return .integerLiteral("")
      case .self:
        return .keyword(.self)
      }
    }
  }
}

extension DifferentiableAttributeArgumentsSyntax {
  @_spi(Diagnostics)
  public enum KindSpecifierOptions: TokenSpecSet {
    case _forward
    case reverse
    case _linear

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._forward):
        self = ._forward
      case TokenSpec(.reverse):
        self = .reverse
      case TokenSpec(._linear):
        self = ._linear
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(._forward):
        self = ._forward
      case TokenSpec(.reverse):
        self = .reverse
      case TokenSpec(._linear):
        self = ._linear
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case ._forward:
        return .keyword(._forward)
      case .reverse:
        return .keyword(.reverse)
      case ._linear:
        return .keyword(._linear)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._forward:
        return .keyword(._forward)
      case .reverse:
        return .keyword(.reverse)
      case ._linear:
        return .keyword(._linear)
      }
    }
  }
}

extension DocumentationAttributeArgumentSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case visibility
    case metadata

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.visibility):
        self = .visibility
      case TokenSpec(.metadata):
        self = .metadata
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.visibility):
        self = .visibility
      case TokenSpec(.metadata):
        self = .metadata
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .visibility:
        return .keyword(.visibility)
      case .metadata:
        return .keyword(.metadata)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .visibility:
        return .keyword(.visibility)
      case .metadata:
        return .keyword(.metadata)
      }
    }
  }
}

extension EnumCaseParameterSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension EnumCaseParameterSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension FunctionDeclSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case binaryOperator
    case prefixOperator
    case postfixOperator

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension FunctionEffectSpecifiersSyntax {
  @_spi(Diagnostics)
  public enum AsyncSpecifierOptions: TokenSpecSet {
    case async
    case reasync

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.async):
        self = .async
      case TokenSpec(.reasync):
        self = .reasync
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.async):
        self = .async
      case TokenSpec(.reasync):
        self = .reasync
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .async:
        return .keyword(.async)
      case .reasync:
        return .keyword(.reasync)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .async:
        return .keyword(.async)
      case .reasync:
        return .keyword(.reasync)
      }
    }
  }
}

extension FunctionParameterSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension FunctionParameterSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension GenericParameterSyntax {
  @_spi(Diagnostics)
  public enum SpecifierOptions: TokenSpecSet {
    case each
    case `let`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.each):
        self = .each
      case TokenSpec(.let):
        self = .let
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.each):
        self = .each
      case TokenSpec(.let):
        self = .let
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .each:
        return .keyword(.each)
      case .let:
        return .keyword(.let)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .each:
        return .keyword(.each)
      case .let:
        return .keyword(.let)
      }
    }
  }
}

extension IdentifierPatternSyntax {
  @_spi(Diagnostics)
  public enum IdentifierOptions: TokenSpecSet {
    case identifier
    case `self`
    case `init`
    case `deinit`
    case `subscript`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.deinit):
        self = .deinit
      case TokenSpec(.subscript):
        self = .subscript
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.deinit):
        self = .deinit
      case TokenSpec(.subscript):
        self = .subscript
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .keyword(.self)
      case .`init`:
        return .keyword(.`init`)
      case .deinit:
        return .keyword(.deinit)
      case .subscript:
        return .keyword(.subscript)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      case .`init`:
        return .keyword(.`init`)
      case .deinit:
        return .keyword(.deinit)
      case .subscript:
        return .keyword(.subscript)
      }
    }
  }
}

extension IdentifierTypeSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case `Self`
    case `Any`
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.Self):
        self = .Self
      case TokenSpec(.Any):
        self = .Any
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.Self):
        self = .Self
      case TokenSpec(.Any):
        self = .Any
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .Self:
        return .keyword(.Self)
      case .Any:
        return .keyword(.Any)
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .Self:
        return .keyword(.Self)
      case .Any:
        return .keyword(.Any)
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension IfConfigClauseSyntax {
  @_spi(Diagnostics)
  public enum PoundKeywordOptions: TokenSpecSet {
    case poundIf
    case poundElseif
    case poundElse

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.poundIf):
        self = .poundIf
      case TokenSpec(.poundElseif):
        self = .poundElseif
      case TokenSpec(.poundElse):
        self = .poundElse
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.poundIf):
        self = .poundIf
      case TokenSpec(.poundElseif):
        self = .poundElseif
      case TokenSpec(.poundElse):
        self = .poundElse
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .poundIf:
        return .poundIf
      case .poundElseif:
        return .poundElseif
      case .poundElse:
        return .poundElse
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .poundIf:
        return .poundIfToken()
      case .poundElseif:
        return .poundElseifToken()
      case .poundElse:
        return .poundElseToken()
      }
    }
  }
}

extension ImportDeclSyntax {
  @_spi(Diagnostics)
  public enum ImportKindSpecifierOptions: TokenSpecSet {
    case `typealias`
    case `struct`
    case `class`
    case `enum`
    case `protocol`
    case `var`
    case `let`
    case `func`
    case `inout`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.typealias):
        self = .typealias
      case TokenSpec(.struct):
        self = .struct
      case TokenSpec(.class):
        self = .class
      case TokenSpec(.enum):
        self = .enum
      case TokenSpec(.protocol):
        self = .protocol
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.func):
        self = .func
      case TokenSpec(.inout):
        self = .inout
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.typealias):
        self = .typealias
      case TokenSpec(.struct):
        self = .struct
      case TokenSpec(.class):
        self = .class
      case TokenSpec(.enum):
        self = .enum
      case TokenSpec(.protocol):
        self = .protocol
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.func):
        self = .func
      case TokenSpec(.inout):
        self = .inout
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .typealias:
        return .keyword(.typealias)
      case .struct:
        return .keyword(.struct)
      case .class:
        return .keyword(.class)
      case .enum:
        return .keyword(.enum)
      case .protocol:
        return .keyword(.protocol)
      case .var:
        return .keyword(.var)
      case .let:
        return .keyword(.let)
      case .func:
        return .keyword(.func)
      case .inout:
        return .keyword(.inout)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .typealias:
        return .keyword(.typealias)
      case .struct:
        return .keyword(.struct)
      case .class:
        return .keyword(.class)
      case .enum:
        return .keyword(.enum)
      case .protocol:
        return .keyword(.protocol)
      case .var:
        return .keyword(.var)
      case .let:
        return .keyword(.let)
      case .func:
        return .keyword(.func)
      case .inout:
        return .keyword(.inout)
      }
    }
  }
}

extension ImportPathComponentSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case binaryOperator
    case prefixOperator
    case postfixOperator

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension InitializerDeclSyntax {
  @_spi(Diagnostics)
  public enum OptionalMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension KeyPathOptionalComponentSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension LabeledExprSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension LabeledSpecializeArgumentSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case target
    case availability
    case exported
    case kind
    case spi
    case spiModule

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.target):
        self = .target
      case TokenSpec(.availability):
        self = .availability
      case TokenSpec(.exported):
        self = .exported
      case TokenSpec(.kind):
        self = .kind
      case TokenSpec(.spi):
        self = .spi
      case TokenSpec(.spiModule):
        self = .spiModule
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.target):
        self = .target
      case TokenSpec(.availability):
        self = .availability
      case TokenSpec(.exported):
        self = .exported
      case TokenSpec(.kind):
        self = .kind
      case TokenSpec(.spi):
        self = .spi
      case TokenSpec(.spiModule):
        self = .spiModule
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .target:
        return .keyword(.target)
      case .availability:
        return .keyword(.availability)
      case .exported:
        return .keyword(.exported)
      case .kind:
        return .keyword(.kind)
      case .spi:
        return .keyword(.spi)
      case .spiModule:
        return .keyword(.spiModule)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .target:
        return .keyword(.target)
      case .availability:
        return .keyword(.availability)
      case .exported:
        return .keyword(.exported)
      case .kind:
        return .keyword(.kind)
      case .spi:
        return .keyword(.spi)
      case .spiModule:
        return .keyword(.spiModule)
      }
    }
  }
}

extension LayoutRequirementSyntax {
  @_spi(Diagnostics)
  public enum LayoutSpecifierOptions: TokenSpecSet {
    case _Trivial
    case _TrivialAtMost
    case _UnknownLayout
    case _RefCountedObject
    case _NativeRefCountedObject
    case _Class
    case _NativeClass
    case _BridgeObject
    case _TrivialStride

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._Trivial):
        self = ._Trivial
      case TokenSpec(._TrivialAtMost):
        self = ._TrivialAtMost
      case TokenSpec(._UnknownLayout):
        self = ._UnknownLayout
      case TokenSpec(._RefCountedObject):
        self = ._RefCountedObject
      case TokenSpec(._NativeRefCountedObject):
        self = ._NativeRefCountedObject
      case TokenSpec(._Class):
        self = ._Class
      case TokenSpec(._NativeClass):
        self = ._NativeClass
      case TokenSpec(._BridgeObject):
        self = ._BridgeObject
      case TokenSpec(._TrivialStride):
        self = ._TrivialStride
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(._Trivial):
        self = ._Trivial
      case TokenSpec(._TrivialAtMost):
        self = ._TrivialAtMost
      case TokenSpec(._UnknownLayout):
        self = ._UnknownLayout
      case TokenSpec(._RefCountedObject):
        self = ._RefCountedObject
      case TokenSpec(._NativeRefCountedObject):
        self = ._NativeRefCountedObject
      case TokenSpec(._Class):
        self = ._Class
      case TokenSpec(._NativeClass):
        self = ._NativeClass
      case TokenSpec(._BridgeObject):
        self = ._BridgeObject
      case TokenSpec(._TrivialStride):
        self = ._TrivialStride
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case ._Trivial:
        return .keyword(._Trivial)
      case ._TrivialAtMost:
        return .keyword(._TrivialAtMost)
      case ._UnknownLayout:
        return .keyword(._UnknownLayout)
      case ._RefCountedObject:
        return .keyword(._RefCountedObject)
      case ._NativeRefCountedObject:
        return .keyword(._NativeRefCountedObject)
      case ._Class:
        return .keyword(._Class)
      case ._NativeClass:
        return .keyword(._NativeClass)
      case ._BridgeObject:
        return .keyword(._BridgeObject)
      case ._TrivialStride:
        return .keyword(._TrivialStride)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._Trivial:
        return .keyword(._Trivial)
      case ._TrivialAtMost:
        return .keyword(._TrivialAtMost)
      case ._UnknownLayout:
        return .keyword(._UnknownLayout)
      case ._RefCountedObject:
        return .keyword(._RefCountedObject)
      case ._NativeRefCountedObject:
        return .keyword(._NativeRefCountedObject)
      case ._Class:
        return .keyword(._Class)
      case ._NativeClass:
        return .keyword(._NativeClass)
      case ._BridgeObject:
        return .keyword(._BridgeObject)
      case ._TrivialStride:
        return .keyword(._TrivialStride)
      }
    }
  }
}

extension LifetimeSpecifierArgumentSyntax {
  @_spi(Diagnostics)
  public enum ParameterOptions: TokenSpecSet {
    case identifier
    case `self`
    case integerLiteral

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .keyword(.self)
      case .integerLiteral:
        return .integerLiteral
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      case .integerLiteral:
        return .integerLiteral("")
      }
    }
  }
}

extension MemberTypeSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case `self`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.self):
        self = .self
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .keyword(.self)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      }
    }
  }
}

extension MetatypeTypeSyntax {
  @_spi(Diagnostics)
  public enum MetatypeSpecifierOptions: TokenSpecSet {
    case `Type`
    case `Protocol`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.Type):
        self = .Type
      case TokenSpec(.Protocol):
        self = .Protocol
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.Type):
        self = .Type
      case TokenSpec(.Protocol):
        self = .Protocol
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .Type:
        return .keyword(.Type)
      case .Protocol:
        return .keyword(.Protocol)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .Type:
        return .keyword(.Type)
      case .Protocol:
        return .keyword(.Protocol)
      }
    }
  }
}

extension MultipleTrailingClosureElementSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension OperatorDeclSyntax {
  @_spi(Diagnostics)
  public enum FixitySpecifierOptions: TokenSpecSet {
    case prefix
    case postfix
    case infix

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.prefix):
        self = .prefix
      case TokenSpec(.postfix):
        self = .postfix
      case TokenSpec(.infix):
        self = .infix
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.prefix):
        self = .prefix
      case TokenSpec(.postfix):
        self = .postfix
      case TokenSpec(.infix):
        self = .infix
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .prefix:
        return .keyword(.prefix)
      case .postfix:
        return .keyword(.postfix)
      case .infix:
        return .keyword(.infix)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .prefix:
        return .keyword(.prefix)
      case .postfix:
        return .keyword(.postfix)
      case .infix:
        return .keyword(.infix)
      }
    }
  }
}

extension OperatorDeclSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case binaryOperator
    case prefixOperator
    case postfixOperator

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension OptionalBindingConditionSyntax {
  @_spi(Diagnostics)
  public enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    #if compiler(>=5.8)
    @_spi(ExperimentalLanguageFeatures)
    #endif
    case _mutating
    case _borrowing
    #if compiler(>=5.8)
    @_spi(ExperimentalLanguageFeatures)
    #endif
    case _consuming

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(._mutating) where experimentalFeatures.contains(.referenceBindings):
        self = ._mutating
      case TokenSpec(._borrowing):
        self = ._borrowing
      case TokenSpec(._consuming) where experimentalFeatures.contains(.referenceBindings):
        self = ._consuming
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(._mutating):
        self = ._mutating
      case TokenSpec(._borrowing):
        self = ._borrowing
      case TokenSpec(._consuming):
        self = ._consuming
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      }
    }
  }
}

extension PrecedenceGroupAssignmentSyntax {
  @_spi(Diagnostics)
  public enum ValueOptions: TokenSpecSet {
    case `true`
    case `false`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.true):
        self = .true
      case TokenSpec(.false):
        self = .false
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.true):
        self = .true
      case TokenSpec(.false):
        self = .false
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .true:
        return .keyword(.true)
      case .false:
        return .keyword(.false)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .true:
        return .keyword(.true)
      case .false:
        return .keyword(.false)
      }
    }
  }
}

extension PrecedenceGroupAssociativitySyntax {
  @_spi(Diagnostics)
  public enum ValueOptions: TokenSpecSet {
    case left
    case right
    case none

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.left):
        self = .left
      case TokenSpec(.right):
        self = .right
      case TokenSpec(.none):
        self = .none
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.left):
        self = .left
      case TokenSpec(.right):
        self = .right
      case TokenSpec(.none):
        self = .none
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .left:
        return .keyword(.left)
      case .right:
        return .keyword(.right)
      case .none:
        return .keyword(.none)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .left:
        return .keyword(.left)
      case .right:
        return .keyword(.right)
      case .none:
        return .keyword(.none)
      }
    }
  }
}

extension PrecedenceGroupRelationSyntax {
  @_spi(Diagnostics)
  public enum HigherThanOrLowerThanLabelOptions: TokenSpecSet {
    case higherThan
    case lowerThan

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.higherThan):
        self = .higherThan
      case TokenSpec(.lowerThan):
        self = .lowerThan
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.higherThan):
        self = .higherThan
      case TokenSpec(.lowerThan):
        self = .lowerThan
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .higherThan:
        return .keyword(.higherThan)
      case .lowerThan:
        return .keyword(.lowerThan)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .higherThan:
        return .keyword(.higherThan)
      case .lowerThan:
        return .keyword(.lowerThan)
      }
    }
  }
}

extension SameTypeRequirementSyntax {
  @_spi(Diagnostics)
  public enum EqualOptions: TokenSpecSet {
    case binaryOperator
    case prefixOperator
    case postfixOperator

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension SimpleStringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum OpeningQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      }
    }
  }
}

extension SimpleStringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum ClosingQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      }
    }
  }
}

extension SimpleTypeSpecifierSyntax {
  @_spi(Diagnostics)
  public enum SpecifierOptions: TokenSpecSet {
    case `inout`
    case __shared
    case __owned
    case isolated
    case _const
    case borrowing
    case consuming
    case sending

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(.__shared):
        self = .__shared
      case TokenSpec(.__owned):
        self = .__owned
      case TokenSpec(.isolated):
        self = .isolated
      case TokenSpec(._const):
        self = ._const
      case TokenSpec(.borrowing):
        self = .borrowing
      case TokenSpec(.consuming):
        self = .consuming
      case TokenSpec(.sending):
        self = .sending
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(.__shared):
        self = .__shared
      case TokenSpec(.__owned):
        self = .__owned
      case TokenSpec(.isolated):
        self = .isolated
      case TokenSpec(._const):
        self = ._const
      case TokenSpec(.borrowing):
        self = .borrowing
      case TokenSpec(.consuming):
        self = .consuming
      case TokenSpec(.sending):
        self = .sending
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .inout:
        return .keyword(.inout)
      case .__shared:
        return .keyword(.__shared)
      case .__owned:
        return .keyword(.__owned)
      case .isolated:
        return .keyword(.isolated)
      case ._const:
        return .keyword(._const)
      case .borrowing:
        return .keyword(.borrowing)
      case .consuming:
        return .keyword(.consuming)
      case .sending:
        return .keyword(.sending)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .inout:
        return .keyword(.inout)
      case .__shared:
        return .keyword(.__shared)
      case .__owned:
        return .keyword(.__owned)
      case .isolated:
        return .keyword(.isolated)
      case ._const:
        return .keyword(._const)
      case .borrowing:
        return .keyword(.borrowing)
      case .consuming:
        return .keyword(.consuming)
      case .sending:
        return .keyword(.sending)
      }
    }
  }
}

extension SomeOrAnyTypeSyntax {
  @_spi(Diagnostics)
  public enum SomeOrAnySpecifierOptions: TokenSpecSet {
    case some
    case any

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.some):
        self = .some
      case TokenSpec(.any):
        self = .any
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.some):
        self = .some
      case TokenSpec(.any):
        self = .any
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .some:
        return .keyword(.some)
      case .any:
        return .keyword(.any)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .some:
        return .keyword(.some)
      case .any:
        return .keyword(.any)
      }
    }
  }
}

extension StringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum OpeningQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    case singleQuote

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      case .singleQuote:
        return .singleQuote
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      case .singleQuote:
        return .singleQuoteToken()
      }
    }
  }
}

extension StringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum ClosingQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    case singleQuote

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      case .singleQuote:
        return .singleQuote
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      case .singleQuote:
        return .singleQuoteToken()
      }
    }
  }
}

extension ThrowsClauseSyntax {
  @_spi(Diagnostics)
  public enum ThrowsSpecifierOptions: TokenSpecSet {
    case `throws`
    case `rethrows`

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.throws):
        self = .throws
      case TokenSpec(.rethrows):
        self = .rethrows
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.throws):
        self = .throws
      case TokenSpec(.rethrows):
        self = .rethrows
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .throws:
        return .keyword(.throws)
      case .rethrows:
        return .keyword(.rethrows)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .throws:
        return .keyword(.throws)
      case .rethrows:
        return .keyword(.rethrows)
      }
    }
  }
}

extension TryExprSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension TupleTypeElementSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension TupleTypeElementSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension UnresolvedAsExprSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension ValueBindingPatternSyntax {
  @_spi(Diagnostics)
  public enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    #if compiler(>=5.8)
    @_spi(ExperimentalLanguageFeatures)
    #endif
    case _mutating
    case _borrowing
    #if compiler(>=5.8)
    @_spi(ExperimentalLanguageFeatures)
    #endif
    case _consuming
    case borrowing

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(._mutating) where experimentalFeatures.contains(.referenceBindings):
        self = ._mutating
      case TokenSpec(._borrowing):
        self = ._borrowing
      case TokenSpec(._consuming) where experimentalFeatures.contains(.referenceBindings):
        self = ._consuming
      case TokenSpec(.borrowing):
        self = .borrowing
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(._mutating):
        self = ._mutating
      case TokenSpec(._borrowing):
        self = ._borrowing
      case TokenSpec(._consuming):
        self = ._consuming
      case TokenSpec(.borrowing):
        self = .borrowing
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      case .borrowing:
        return .keyword(.borrowing)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      case .borrowing:
        return .keyword(.borrowing)
      }
    }
  }
}

extension VariableDeclSyntax {
  @_spi(Diagnostics)
  public enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    #if compiler(>=5.8)
    @_spi(ExperimentalLanguageFeatures)
    #endif
    case _mutating
    case _borrowing
    #if compiler(>=5.8)
    @_spi(ExperimentalLanguageFeatures)
    #endif
    case _consuming

    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(._mutating) where experimentalFeatures.contains(.referenceBindings):
        self = ._mutating
      case TokenSpec(._borrowing):
        self = ._borrowing
      case TokenSpec(._consuming) where experimentalFeatures.contains(.referenceBindings):
        self = ._consuming
      default:
        return nil
      }
    }

    public init?(token: TokenSyntax) {
      switch token {
      case TokenSpec(.let):
        self = .let
      case TokenSpec(.var):
        self = .var
      case TokenSpec(.inout):
        self = .inout
      case TokenSpec(._mutating):
        self = ._mutating
      case TokenSpec(._borrowing):
        self = ._borrowing
      case TokenSpec(._consuming):
        self = ._consuming
      default:
        return nil
      }
    }

    var spec: TokenSpec {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      }
    }

    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      }
    }
  }
}
